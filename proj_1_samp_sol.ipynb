{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 1 - NLP and Text Classification\n",
    "\n",
    "For this project you will need to classify some angry comments into their respective category of angry. The process that you'll need to follow is (roughly):\n",
    "<ol>\n",
    "<li> Use NLP techniques to process the training data. \n",
    "<li> Train model(s) to predict which class(es) each comment is in.\n",
    "    <ul>\n",
    "    <li> A comment can belong to any number of classes, including none. \n",
    "    </ul>\n",
    "<li> Generate predictions for each of the comments in the test data. \n",
    "<li> Write your test data predicitions to a CSV file, which will be scored. \n",
    "</ol>\n",
    "\n",
    "You can use any models and NLP libraries you'd like. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What I Got\n",
    "\n",
    "My results ended up being fairly simple, I didn't see much of an increase in accuracy in making the model more complex. Trials on the test data generally gave me around 94% to 96% accuracy overall. \n",
    "\n",
    "<ul>\n",
    "<li> I used the tfidf vectorizer. I didn't get much of an increase (maybe ~1%) using Word2Vec in the toxic data, so I dropped it. \n",
    "<li> I used Bayes as my classifier - this was more of a compromise to practicality, though the accuracy is good. NB is fast, and I ran this many, many, many times, so it made a lot of sense in this case. \n",
    "<li> I tried oversampling since the dataset is so imbalanced, but scores generally went down fractionally when I did so. \n",
    "<li> Training the models on the full dataset after model selection improved accuracy a point or two. \n",
    "<ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data\n",
    "\n",
    "Use the training data to train your prediction model(s). Each of the classification output columns (toxic to the end) is a human label for the comment_text, assessing if it falls into that category of \"rude\". A comment may fall into any number of categories, or none at all. Membership in one output category is <b>independent</b> of membership in any of the other classes (think about this when you plan on how to make these predictions - it may also make it easier to split work amongst a team...). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.csv.zip\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I didn't end up using the none column in the end. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>none</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59178</th>\n",
       "      <td>9e865aaf9b98dac0</td>\n",
       "      <td>\":::::::Sarbajit, there is another book by the...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45024</th>\n",
       "      <td>785deba849f6021c</td>\n",
       "      <td>| class=B | importance=Top</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120210</th>\n",
       "      <td>82ebd3e08cc7a2ae</td>\n",
       "      <td>Trusilver....you have gone too far and I inten...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24648</th>\n",
       "      <td>412d5838e658948a</td>\n",
       "      <td>\"\\n\\n Good reference from German side of Derfl...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148325</th>\n",
       "      <td>4a8d6552b00df960</td>\n",
       "      <td>Yeah, it is true: it is correct to write Movim...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151405</th>\n",
       "      <td>7c856efda7a634d9</td>\n",
       "      <td>The added content is speculative and your expl...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157120</th>\n",
       "      <td>d8e18502e65a8d30</td>\n",
       "      <td>\"Hi again MjolnirPants. Sorry again, but  keep...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6220</th>\n",
       "      <td>109ba83f2f3edb6b</td>\n",
       "      <td>\"\\n\\nKosovo is de jure a province of Serbia.  ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155268</th>\n",
       "      <td>bb59e78acbca5e66</td>\n",
       "      <td>In which case, rather than assuming anything, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4276</th>\n",
       "      <td>0b69af59048dde56</td>\n",
       "      <td>Merge \\n\\nIt has been suggested that the artic...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "59178   9e865aaf9b98dac0  \":::::::Sarbajit, there is another book by the...   \n",
       "45024   785deba849f6021c                         | class=B | importance=Top   \n",
       "120210  82ebd3e08cc7a2ae  Trusilver....you have gone too far and I inten...   \n",
       "24648   412d5838e658948a  \"\\n\\n Good reference from German side of Derfl...   \n",
       "148325  4a8d6552b00df960  Yeah, it is true: it is correct to write Movim...   \n",
       "151405  7c856efda7a634d9  The added content is speculative and your expl...   \n",
       "157120  d8e18502e65a8d30  \"Hi again MjolnirPants. Sorry again, but  keep...   \n",
       "6220    109ba83f2f3edb6b  \"\\n\\nKosovo is de jure a province of Serbia.  ...   \n",
       "155268  bb59e78acbca5e66  In which case, rather than assuming anything, ...   \n",
       "4276    0b69af59048dde56  Merge \\n\\nIt has been suggested that the artic...   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  none  \n",
       "59178       0             0        0       0       0              0     1  \n",
       "45024       0             0        0       0       0              0     1  \n",
       "120210      0             0        0       0       0              0     1  \n",
       "24648       0             0        0       0       0              0     1  \n",
       "148325      0             0        0       0       0              0     1  \n",
       "151405      0             0        0       0       0              0     1  \n",
       "157120      0             0        0       0       0              0     1  \n",
       "6220        0             0        0       0       0              0     1  \n",
       "155268      0             0        0       0       0              0     1  \n",
       "4276        0             0        0       0       0              0     1  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Construct a \"None\" column for comments that are not in any category\n",
    "train_df[\"none\"] = ((train_df.toxic | train_df.severe_toxic | train_df.obscene | train_df.threat | train_df.insult | train_df.identity_hate) == 0)\n",
    "train_df[\"none\"] = train_df[\"none\"].astype(int)\n",
    "train_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/akeems/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Text preprocess\n",
    "nltk.download(\"stopwords\")\n",
    "corpus = []\n",
    "for i in range(1, 1000):\n",
    "    #Remove punctuation\n",
    "    review = re.sub(\"[^a-zA-Z]\", \" \", train_df[\"comment_text\"][i])\n",
    "    #Normalize to lower case\n",
    "    review = review.lower()\n",
    "    #Split into sentences\n",
    "    review = review.split()\n",
    "    #Remove stopwords\n",
    "    ps = PorterStemmer()\n",
    "    review = [ps.stem(word) for word in review if not word in set(stopwords.words(\"english\"))]\n",
    "    review = \" \".join(review)\n",
    "    corpus.append(review)\n",
    "#At this point the corpus is clean text - free of basic \"junk\". It is its own list at the moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make X dataset for modelling\n",
    "#cv = CountVectorizer(max_features = 1500)\n",
    "#X = cv.fit_transform(corpus).toarray()\n",
    "\n",
    "#Make y datasets for modelling\n",
    "y_t_1 = np.array(train_df[\"toxic\"]).reshape(-1,1)\n",
    "y_st_2 = np.array(train_df[\"severe_toxic\"]).reshape(-1,1)\n",
    "y_o_3 = np.array(train_df[\"obscene\"]).reshape(-1,1)\n",
    "y_th_4 = np.array(train_df[\"threat\"]).reshape(-1,1)\n",
    "y_i_5 = np.array(train_df[\"insult\"]).reshape(-1,1)\n",
    "y_ih_6 = np.array(train_df[\"identity_hate\"]).reshape(-1,1)\n",
    "y_n_7 = np.array(train_df[\"none\"]).reshape(-1,1)\n",
    "list_targets = [y_t_1, y_st_2, y_o_3, y_th_4, y_i_5, y_ih_6, y_n_7]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([144277,  15294]))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Balance\n",
    "np.unique(y_t_1, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try Oversample\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import make_pipeline\n",
    "oversample = RandomOverSampler(sampling_strategy='minority')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     36051\n",
      "           1       0.99      0.15      0.25      3842\n",
      "\n",
      "    accuracy                           0.92     39893\n",
      "   macro avg       0.95      0.57      0.61     39893\n",
      "weighted avg       0.92      0.92      0.89     39893\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['toxic.joblib']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NB Model\n",
    "vector_nb_1 = TfidfVectorizer()\n",
    "model_nb_1 = MultinomialNB()\n",
    "#model_nb_1 = RandomForestClassifier()\n",
    "stemmer_1 = PorterStemmer()\n",
    "#lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "X_1 = train_df[\"comment_text\"]\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X_1, y_t_1)\n",
    "\n",
    "# Use original data\n",
    "pipe_nb_1 = Pipeline([(\"vect\", vector_nb_1),(\"model\", model_nb_1)])\n",
    "# Use oversample\n",
    "#pipe_nb_1 = make_pipeline(vector_nb_1, oversample, model_nb_1)\n",
    "\n",
    "pipe_nb_1.fit(X_train_1, y_train_1.ravel())\n",
    "preds_1 = pipe_nb_1.predict(X_test_1)\n",
    "#pipe_nb.score(X_test,y_test)\n",
    "print(classification_report(y_test_1, preds_1))\n",
    "confusion_matrix(y_test_1, preds_1)\n",
    "\n",
    "#Retrain with full dataset\n",
    "pipe_nb_1.fit(X_1, y_t_1.ravel())\n",
    "dump(pipe_nb_1, \"toxic.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversample\n",
    "\n",
    "I tried oversampling, but I didn't get better results, so I dropped it here. Below I will include it where it looks to give an improvement. It looks like the ones that are very skewed tend to show an improvement. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Severe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([157976,   1595]))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_st_2, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     39492\n",
      "           1       0.00      0.00      0.00       401\n",
      "\n",
      "    accuracy                           0.99     39893\n",
      "   macro avg       0.49      0.50      0.50     39893\n",
      "weighted avg       0.98      0.99      0.98     39893\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', TfidfVectorizer()), ('model', MultinomialNB())])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NB Model\n",
    "vector_nb_2 = TfidfVectorizer()\n",
    "model_nb_2 = MultinomialNB()\n",
    "#model_nb_2 = RandomForestClassifier()\n",
    "stemmer_2 = PorterStemmer()\n",
    "\n",
    "X_2 = train_df[\"comment_text\"]\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, y_st_2)\n",
    "\n",
    "pipe_nb_2 = Pipeline([ (\"vect\", vector_nb_2),(\"model\", model_nb_2)])\n",
    "#pipe_nb_2 = make_pipeline(vector_nb_2, oversample, model_nb_2)\n",
    "\n",
    "pipe_nb_2.fit(X_train_2, y_train_2.ravel())\n",
    "preds_2 = pipe_nb_2.predict(X_test_2)\n",
    "#pipe_nb.score(X_test,y_test)\n",
    "print(classification_report(y_test_2, preds_2))\n",
    "confusion_matrix(y_test_2, preds_2)\n",
    "\n",
    "#Retrain with full dataset\n",
    "pipe_nb_2.fit(X_2, y_st_2.ravel())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obscene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([151122,   8449]))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_o_3, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97     37766\n",
      "           1       0.97      0.09      0.16      2127\n",
      "\n",
      "    accuracy                           0.95     39893\n",
      "   macro avg       0.96      0.54      0.57     39893\n",
      "weighted avg       0.95      0.95      0.93     39893\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', TfidfVectorizer()), ('model', MultinomialNB())])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NB Model\n",
    "vector_nb_3 = TfidfVectorizer()\n",
    "model_nb_3 = MultinomialNB()\n",
    "#model_nb_3 = RandomForestClassifier()\n",
    "stemmer_3 = PorterStemmer()\n",
    "\n",
    "X_3 = train_df[\"comment_text\"]\n",
    "X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(X_3, y_o_3)\n",
    "\n",
    "pipe_nb_3 = Pipeline([ (\"vect\", vector_nb_3),(\"model\", model_nb_3)])\n",
    "#pipe_nb_3 = make_pipeline(vector_nb_3, oversample, model_nb_3)\n",
    "\n",
    "pipe_nb_3.fit(X_train_3, y_train_3.ravel())\n",
    "preds_3 = pipe_nb_3.predict(X_test_3)\n",
    "#pipe_nb.score(X_test,y_test)\n",
    "print(classification_report(y_test_3, preds_3))\n",
    "confusion_matrix(y_test_3, preds_3)\n",
    "\n",
    "#Retrain with full dataset\n",
    "pipe_nb_3.fit(X_3, y_o_3.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([159093,    478]))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_th_4, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     39788\n",
      "           1       0.05      0.72      0.09       105\n",
      "\n",
      "    accuracy                           0.96     39893\n",
      "   macro avg       0.52      0.84      0.53     39893\n",
      "weighted avg       1.00      0.96      0.98     39893\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer()),\n",
       "                ('randomoversampler',\n",
       "                 RandomOverSampler(sampling_strategy='minority')),\n",
       "                ('multinomialnb', MultinomialNB())])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NB Model\n",
    "vector_nb_4 = TfidfVectorizer()\n",
    "model_nb_4 = MultinomialNB()\n",
    "#model_nb_4 = RandomForestClassifier()\n",
    "stemmer_4 = PorterStemmer()\n",
    "\n",
    "X_4 = train_df[\"comment_text\"]\n",
    "X_train_4, X_test_4, y_train_4, y_test_4 = train_test_split(X_4, y_th_4)\n",
    "\n",
    "#pipe_nb_4 = Pipeline([ (\"vect\", vector_nb_4),(\"model\", model_nb_4)])\n",
    "pipe_nb_4 = make_pipeline(vector_nb_4, oversample, model_nb_4)\n",
    "\n",
    "pipe_nb_4.fit(X_train_4, y_train_4.ravel())\n",
    "preds_4 = pipe_nb_4.predict(X_test_4)\n",
    "#pipe_nb.score(X_test,y_test)\n",
    "print(classification_report(y_test_4, preds_4))\n",
    "confusion_matrix(y_test_4, preds_4)\n",
    "\n",
    "#Retrain with full dataset\n",
    "pipe_nb_4.fit(X_4, y_th_4.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([151694,   7877]))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_i_5, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98     37919\n",
      "           1       0.96      0.03      0.06      1974\n",
      "\n",
      "    accuracy                           0.95     39893\n",
      "   macro avg       0.95      0.52      0.52     39893\n",
      "weighted avg       0.95      0.95      0.93     39893\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', TfidfVectorizer()), ('model', MultinomialNB())])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NB Model\n",
    "vector_nb_5 = TfidfVectorizer()\n",
    "model_nb_5 = MultinomialNB()\n",
    "#model_nb_5 = RandomForestClassifier()\n",
    "stemmer_5 = PorterStemmer()\n",
    "\n",
    "X_5 = train_df[\"comment_text\"]\n",
    "X_train_5, X_test_5, y_train_5, y_test_5 = train_test_split(X_5, y_i_5)\n",
    "\n",
    "pipe_nb_5 = Pipeline([ (\"vect\", vector_nb_5),(\"model\", model_nb_5)])\n",
    "#pipe_nb_5 = make_pipeline(vector_nb_5, oversample, model_nb_5)\n",
    "\n",
    "pipe_nb_5.fit(X_train_5, y_train_5.ravel())\n",
    "preds_5 = pipe_nb_5.predict(X_test_5)\n",
    "#pipe_nb.score(X_test,y_test)\n",
    "print(classification_report(y_test_5, preds_5))\n",
    "confusion_matrix(y_test_5, preds_5)\n",
    "\n",
    "#Retrain with full dataset\n",
    "pipe_nb_5.fit(X_5, y_i_5.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identity Hate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([158166,   1405]))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_ih_6, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97     39547\n",
      "           1       0.10      0.78      0.18       346\n",
      "\n",
      "    accuracy                           0.94     39893\n",
      "   macro avg       0.55      0.86      0.58     39893\n",
      "weighted avg       0.99      0.94      0.96     39893\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer()),\n",
       "                ('randomoversampler',\n",
       "                 RandomOverSampler(sampling_strategy='minority')),\n",
       "                ('multinomialnb', MultinomialNB())])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NB Model\n",
    "vector_nb_6 = TfidfVectorizer()\n",
    "model_nb_6 = MultinomialNB()\n",
    "#model_nb_6 = RandomForestClassifier()\n",
    "stemmer_6 = PorterStemmer()\n",
    "\n",
    "X_6 = train_df[\"comment_text\"]\n",
    "X_train_6, X_test_6, y_train_6, y_test_6 = train_test_split(X_6, y_ih_6)\n",
    "\n",
    "#pipe_nb_6 = Pipeline([ (\"vect\", vector_nb_6),(\"model\", model_nb_6)])\n",
    "pipe_nb_6 = make_pipeline(vector_nb_6, oversample, model_nb_6)\n",
    "\n",
    "pipe_nb_6.fit(X_train_6, y_train_6.ravel())\n",
    "preds_6 = pipe_nb_6.predict(X_test_6)\n",
    "#pipe_nb.score(X_test,y_test)\n",
    "print(classification_report(y_test_6, preds_6))\n",
    "confusion_matrix(y_test_6, preds_6)\n",
    "\n",
    "#Retrain with full dataset\n",
    "pipe_nb_6.fit(X_6, y_ih_6.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think this one was impacted by the balance in my test. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                       comment_text\n",
       "0   1  Yo bitch Ja Rule is more succesful then you'll...\n",
       "1   2  == From RfC == \\n\\n The title is fine as it is...\n",
       "2   3  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
       "3   4  :If you have a look back at the source, the in...\n",
       "4   5          I don't anonymously edit articles at all."
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"test.csv\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([147594,   5570]))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Toxic Predictions\n",
    "pipe_nb_1 = load(\"toxic.joblib\")\n",
    "nb_preds_1 = pipe_nb_1.predict(test_df[\"comment_text\"])\n",
    "np.unique(nb_preds_1, return_counts=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([153159,      5]))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Severe Toxic Predictions\n",
    "nb_preds_2 = pipe_nb_2.predict(test_df[\"comment_text\"])\n",
    "np.unique(nb_preds_2, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([151335,   1829]))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obscene Predictions\n",
    "nb_preds_3 = pipe_nb_3.predict(test_df[\"comment_text\"])\n",
    "np.unique(nb_preds_3, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([139881,  13283]))"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Threat Predictions\n",
    "nb_preds_4 = pipe_nb_4.predict(test_df[\"comment_text\"])\n",
    "np.unique(nb_preds_4, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([152443,    721]))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insult Predictions\n",
    "nb_preds_5 = pipe_nb_5.predict(test_df[\"comment_text\"])\n",
    "np.unique(nb_preds_5, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([130935,  22229]))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identity Hate Predictions\n",
    "nb_preds_6 = pipe_nb_6.predict(test_df[\"comment_text\"])\n",
    "np.unique(nb_preds_6, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                       comment_text  toxic  severe_toxic  \\\n",
       "0   1  Yo bitch Ja Rule is more succesful then you'll...      0             0   \n",
       "1   2  == From RfC == \\n\\n The title is fine as it is...      0             0   \n",
       "2   3  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...      0             0   \n",
       "3   4  :If you have a look back at the source, the in...      0             0   \n",
       "4   5          I don't anonymously edit articles at all.      0             0   \n",
       "\n",
       "   obscene  threat  insult  identity_hate  \n",
       "0        0       1       0              1  \n",
       "1        0       0       0              0  \n",
       "2        0       0       0              0  \n",
       "3        0       0       0              0  \n",
       "4        0       0       0              0  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[\"toxic\"] = nb_preds_1\n",
    "test_df[\"severe_toxic\"] = nb_preds_2\n",
    "test_df[\"obscene\"] = nb_preds_3\n",
    "test_df[\"threat\"] = nb_preds_4\n",
    "test_df[\"insult\"] = nb_preds_5\n",
    "test_df[\"identity_hate\"] = nb_preds_6\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df.info()\n",
    "test_df.to_csv('out.csv', index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Details, Submission Info, and Example Submission\n",
    "\n",
    "For this project, please output your predictions in a CSV file. The structure of the CSV file should match the structure of the example below. \n",
    "\n",
    "The output should contain one row for each row of test data, complete with the columns for ID and each classification.\n",
    "\n",
    "Into Moodle please submit:\n",
    "<ul>\n",
    "<li> Your notebook file(s). I'm not going to run them, just look. \n",
    "<li> Your sample submission CSV. This will be evaluated for accuracy against the real labels; only a subset of the predictions will be scored. \n",
    "</ul>\n",
    "\n",
    "It is REALLY, REALLY, REALLY important the the structure of your output matches the specifications. The accuracies will be calculated by a script, and it is expecting a specific format. \n",
    "\n",
    "### Sample Evaluator\n",
    "\n",
    "The file prediction_evaluator.ipynb contains an example scoring function, scoreChecker. This function takes a sumbission and an answer key, loops through, and evaluates the accuracy. You can use this to verify the format of your submission. I'm going to use the same function to evaluate the accuracy of your submission, against the answer key (unless I made some mistake in this counting function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dfasdf234</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>asdfgw43r52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>asdgtawe4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wqtr215432</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "0    dfasdf234      0             0        0       0       0              0\n",
       "1  asdfgw43r52      0             0        1       1       0              1\n",
       "2    asdgtawe4      0             0        1       0       1              1\n",
       "3   wqtr215432      0             0        0       1       0              0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Construct dummy data for a sample output. \n",
    "#You won't do this part, you have real data\n",
    "#Your data should have the same structure, so the CSV output is the same\n",
    "dummy_ids = [\"dfasdf234\", \"asdfgw43r52\", \"asdgtawe4\", \"wqtr215432\"]\n",
    "dummy_toxic = [0,0,0,0]\n",
    "dummy_severe = [0,0,0,0]\n",
    "dummy_obscene = [0,1,1,0]\n",
    "dummy_threat = [0,1,0,1]\n",
    "dummy_insult = [0,0,1,0]\n",
    "dummy_ident = [0,1,1,0]\n",
    "columns = [\"id\", \"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "sample_out = pd.DataFrame( list(zip(dummy_ids, dummy_toxic, dummy_severe, dummy_obscene, dummy_threat, dummy_insult, dummy_ident)),\n",
    "                    columns=columns)\n",
    "sample_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write DF to CSV. Please keep the \"out.csv\" filename. Moodle will auto-preface it with an identifier when I download it. \n",
    "#This command should work with your dataframe of predictions. \n",
    "#sample_out.to_csv('out.csv', index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading\n",
    "\n",
    "The grading for this is split between accuracy and well written code:\n",
    "<ul>\n",
    "<li> 75% - Accuracy. The most accurate will get 100% on this, the others will be scaled down from there. \n",
    "<li> 25% - Code quality. Can the code be followed and made sense of - i.e. comments, sections, titles. \n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4d722d3adfa415172c1f5238b519fb86b488acdae450fd691ab06c09f4ca9173"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ml3950': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
